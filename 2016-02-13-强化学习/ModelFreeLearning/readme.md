
### Monte Carlo

#### on_policy
policy greedy   
[3 2 1 3 3]  0.1   
[3 2 3 3 3]  0.1   
[1 2 1 3 3]  0.1   

[3 2 1 3 3]  0.01
[3 0 3 1 2]  0.01   
[3 0 1 3 3]  0.01   
[3 2 3 3 3]  0.01   
[1 0 1 3 3]  0.01
[3 2 3 3 3]  0.01
[3 0 1 1 3]  0.01

#### off_policy
policy greedy   
[3 0 1 3 3]  0.01
[1 2 3 1 0]  0.01   
[3 2 0 3 0]  0.01   
[3 2 3 1 3]  0.1   
[1 2 1 3 3]  0.1   
[3 2 1 0 3]  0.1   

##### 单个奖赏为重要性奖赏

[3 2 1 3 3]   
[3 2 3 3 3]   
[1 2 1 1 3]   
[3 2 1 3 3]   
[3 2 3 3 3]   
[3 2 1 3 2]   
[3 2 3 3 3]
[3 0 1 3 3]

##### 平均奖赏为重要性奖赏

[1 0 3 3 3]   
[3 0 1 3 3]   
[3 0 1 3 3]   
[3 2 1 3 0]   
[1 0 1 1 3]   
[3 2 1 3 3]   
[3 0 3 3 0]   
[3 0 3 3 3]   
[3 1 1 3 3]   


### Temporal Difference

采用西瓜浇水的模型得出的策略

#### Sarsa
[0 0 1 0]

#### Q-Learning
[0 0 1 0]

